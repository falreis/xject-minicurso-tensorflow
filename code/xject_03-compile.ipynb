{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IFMG](https://images.even3.com.br/sBWZnWPFUBgLOGciSZc4G5ZQy7Q=/1100x440/smart/even3.blob.core.windows.net/banner/ARTEPARASITE3.993b3db9f908426e9833.png)\n",
    "\n",
    "---\n",
    "\n",
    "# Introdução ao Tensorflow - Parte 3\n",
    "\n",
    "---\n",
    "\n",
    "#### Professor: Felipe Reis\n",
    "\n",
    "#### Data: 20-10-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Importação de bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "#import plot_images\n",
    "from xject_helper import xject_helper as helper\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Base de Dados CIFAR-10\n",
    "\n",
    "A base de dados CIFAR-10 consiste em 60.000 imagens coloridas de 32x32, divididas em 10 classes.\n",
    "Cada classe contém 6.000 imagens por classe. \n",
    "O conjunto é dividido em 50.000 imagens de treinamento e 10.000 imagens de teste.\n",
    "\n",
    "CIFAR é o acrônimo de Canadian Institute For Advanced Research, proprietário da base de dados.\n",
    "O CIFAR-10 e CIFAR-100 são subconjuntos rotulados de uma base de dados de pequenas imagens que contém 80 milhões de amostras. \n",
    "\n",
    "As imagens foram coletadas por Alex Krizhevsky, Vinod Nair e Geoffrey Hinton.\n",
    "\n",
    "A base está disponível em: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "Ela também está disponível na página do Tensorflow: https://www.tensorflow.org/datasets/catalog/cifar10\n",
    "\n",
    "![CIFAR 10](https://cdn-images-1.medium.com/max/1200/1*SZnidBt7CQ4Xqcag6rd8Ew.png)\n",
    "\n",
    "Fonte: *Jannik Zürn. **Training a CIFAR-10 classifier in the cloud using TensorFlow and Google Colab**. 2018. Disponível em: https://jannik-zuern.medium.com/training-a-cifar-10-classifier-in-the-cloud-using-tensorflow-and-google-colab-f3a5fbdfe24d. Acesso em: 05 de outubro de 2021.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download da base de dados\n",
    "cifar10 = keras.datasets.cifar10\n",
    "\n",
    "#divisão em base de treinamento e testes (subdividido em imagens e labels)\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "#remove 1 dimensão dos arrays de label\n",
    "train_labels = np.squeeze(train_labels)\n",
    "test_labels = np.squeeze(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impressão da quantidade de imagens da base\n",
    "print('Conjunto treino: {} amostras'.format(len(train_images)))\n",
    "print('Conjunto teste: {} amostras'.format(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicao dos nomes das classes\n",
    "class_names = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Veado', \n",
    "               'Cachorro', 'Sapo', 'Cavalo', 'Barco', 'Caminhão']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_images(train_images, train_labels, class_names, random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pré processamento\n",
    "\n",
    "Podemos classificar o conjunto de dados utilizando os mesmos modelos utilizados no último no Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pré processamento\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_images(train_images, train_labels, class_names, random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Treinamento do Modelo\n",
    "\n",
    "O modelo de rede neural abaixo é baseado na arquitetura existente no Notebook 1.\n",
    "\n",
    "Para adequação ao conjunto CIFAR-10, a entrada foi alterada para suportar imagens de tamanho 32 $\\times$ 32 pixels, com 3 canais de cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    #modelo de rede sequencial\n",
    "    return keras.Sequential([\n",
    "        #transforma a image em um array de imagens de três dimensões (32 x 32 x 3)\n",
    "        keras.layers.Flatten(input_shape=(32, 32, 3)), \n",
    "\n",
    "        #Camada de dados totalmente conectadas, com ativação relu\n",
    "        #A camada possui 128 nós (neurônios)\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "        #Camada de dados totalmente conectadas, com ativação softmax\n",
    "        #A camada possui 10 nós (neurônios), correspondentes às probabilidades de cada classe (10 classes)\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compilação do Modelo\n",
    "\n",
    "\n",
    "### Configurações de Compilação\n",
    "\n",
    "Nesta seção serão detalhadas as algumas configurações de compilação do modelo, possibilitando alterar o otimizador, a função de perda e as métricas de qualidade.\n",
    "\n",
    "Neste processo, concentraremos nosso estudo no comando `model.compile`.\n",
    "\n",
    "Informações mais detalhadas e outros parâmetros podem ser encontradas no link: https://keras.io/api/models/model_training_apis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Funções de Perda\n",
    "\n",
    "O objetivo da função de perda (*loss function*) é calcular o quanto o resultado predito pelo modelo é similar ao resultado esperado.\n",
    "\n",
    "Nesse contexto, a função de perda busca minimizar a diferença entre os valores preditos e esperados. Em otimização, a função de perda (ou função de custo ou função de erro) é definido como o oposto da função objetivo.\n",
    "\n",
    "A função de perda é uma função matemática cujo resultado não está limitado a um intervalo de valores. Com isso, a função de perda pode exibir resultados cuja compreensão pode não ser trivial (ex.: loss = 751.35). Esses valores são calculados e não são normalizados, ou seja, dependem da quantidade de amostras do conjunto, da quantidade de classes, do tamanho das imagens, entre outros atributos.\n",
    "\n",
    "A comparação entre perdas de dois problemas diferentes pode não ser trivial.\n",
    "\n",
    "Para alterar a função de perda, devemos utilizar o atributo `loss`.\n",
    "\n",
    "Mais informações podem ser encontradas no link: https://keras.io/api/losses/\n",
    "\n",
    "#### Funções de Perda para Classificação\n",
    "\n",
    "Para treinamento da rede, podemos utilizar diferentes funções de perda. De acordo com a tarefa e a representação de dados utilizada, podemos escolher a função mais adequada. Seguem abaixo algumas funções de perda comuns.\n",
    "\n",
    "A função `binary_crossentropy` calcula o [*cross entropy*](https://en.wikipedia.org/wiki/Cross_entropy) (entropia cruzada) entre rótulos verdadeiros e rótulos previstos, em problemas de classificação binária (0 ou 1). \n",
    "\n",
    "A função `categorical_crossentropy` calcula o [*cross entropy*](https://en.wikipedia.org/wiki/Cross_entropy) (entropia cruzada) entre rótulos verdadeiros e rótulos previstos em problemas de classificação categórica. Essa função, no entanto, requer que os rótulos sejam fornecidos em uma representação [*one_hot*](https://minerandodados.com.br/one-hot-encoding-como-funciona-python/). Esse tipo de codificação é usada para evitar que exista influência da codificação numérica das classes sobre o resultado final do algoritmo.\n",
    "\n",
    "A função `sparse_categorical_crossentropy` calcula o [*cross entropy*](https://en.wikipedia.org/wiki/Cross_entropy) (entropia cruzada) entre rótulos verdadeiros e rótulos previstos em problemas de classificação categórica. Essa função é uma alternativa à função `categorical_crossentropy`, não exigindo que os dados estejam em formato [*one_hot*](https://minerandodados.com.br/one-hot-encoding-como-funciona-python/).\n",
    "\n",
    "A função `kl_divergence` calcula a [divergência de Kullback-Leibler](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) entre rótulos verdadeiros e rótulos previstos em problemas de classificação categórica.\n",
    "\n",
    "A função `categorical_hinge` calcula o [*hinge loss*](https://en.wikipedia.org/wiki/Hinge_loss) entre rótulos verdadeiros e rótulos previstos em problemas de classificação categórica.  Essa função, no entanto, requer que os rótulos sejam fornecidos em uma representação [*one_hot*](https://minerandodados.com.br/one-hot-encoding-como-funciona-python/).\n",
    "\n",
    "O Keras conta com outras funções de perda. Além disso, é possível programar outras funções de perda, para melhor desempenho do algoritmo (ou para tarefas cuja função de perda deva ter um comportamento distinto).\n",
    "\n",
    "\n",
    "#### Funções de Perda para Regressão\n",
    "\n",
    "Para problemas de regressão, podemos utilizar funções de perda mais adequadas à tarefa. \n",
    "\n",
    "Entre as principais funções de perda, destacam-se as seguintes funções:\n",
    "\n",
    "- Similaridade por Cosseno ([Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)), definida pelo comando `cosine_similarity`;\n",
    "- Erro Quadrático Médio ([MSE - Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error)), definida pelo comando `mean_squared_error`;\n",
    "- Erro Absoluto Médio ([MAE - Mean Absolute Error](https://en.wikipedia.org/wiki/Mean_absolute_error)) , definida pelo comando `mean_absolute_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model()\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "model1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model()\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "model1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função Categorical Cross Entropy\n",
    "\n",
    "Podemos converter nossos rótulos (*labels*) para o formato *one hot*, com auxílio do código abaixo.\n",
    "\n",
    "Essa transformação permite que utilizemos a função `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = train_labels\n",
    "depth = 10\n",
    "\n",
    "one_hot_train_labels = tf.one_hot(indices, depth)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(one_hot_train_labels.shape)\n",
    "print(one_hot_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model()\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "model1.fit(train_images, one_hot_train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Métricas\n",
    "\n",
    "A métrica é uma função usada para avaliar o desempenho de um modelo de rede neural.\n",
    "\n",
    "As métricas não são utilizadas para treinamento da rede. Somente fornecem uma informação estatística a respeito da qualidade dos resultados (intermediários ou finais).\n",
    "\n",
    "Ao contrário da função de perda, a métrica normalmente é limitada a um intervalo de valores, possibilitando a comparação de resultados de forma trivial. Devido a sua natureza, os valores, em geral, são limitados ao intervalo 0-100. \n",
    "\n",
    "Métricas não são adequadas como funções de perda uma vez que os resultados somente indicam \"acertos\" e \"erros\", sem expressar a evolução do treinamento (ex.: a métrica não melhorou, porém a previsão foi mais próxima do rótulo verdadeiro, indicando que o algoritmo está melhorando - o que é possível com a função de perda).\n",
    "\n",
    "Em alguns cenários, pode ser vantajoso utilizar as próprias funções de perda (como em problemas de regressão). Não há restrições quanto a isso.\n",
    "\n",
    "Para alterar, adicionar ou remover métricas, podemos o atributo `metrics`.\n",
    "\n",
    "Mais informações podem ser encontradas no link: https://keras.io/api/metrics/\n",
    "\n",
    "\n",
    "#### Métricas para Classificação\n",
    "\n",
    "- [Acurácia](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class);\n",
    "- [Acurácia Binária](https://keras.io/api/metrics/accuracy_metrics/#binaryaccuracy-class);\n",
    "- [Acurácia Categórica](https://keras.io/api/metrics/accuracy_metrics/#categoricalaccuracy-class);\n",
    "- [Precisão](https://keras.io/api/metrics/classification_metrics/#precision-class);\n",
    "- [Revocação](https://keras.io/api/metrics/classification_metrics/#recall-class);\n",
    "- [AUC](https://keras.io/api/metrics/classification_metrics/#auc-class).\n",
    "\n",
    "#### Métricas para Regressão\n",
    "\n",
    "- [Cosine Similarity](https://keras.io/api/metrics/regression_metrics/#cosinesimilarity-class);\n",
    "- [MSE](https://keras.io/api/metrics/regression_metrics/#meansquarederror-class);\n",
    "- [MAE](https://keras.io/api/metrics/regression_metrics/#meanabsoluteerror-class).\n",
    "\n",
    "#### Métricas para Segmentação\n",
    "\n",
    "Interseção sobre União Média (*Mean Intersection-Over-Union*) é uma métrica de avaliação de segmentação semântica de imagens. Primeiro calcula o IOU para cada classe semântica e, em seguida, calcula a média sobre as classes.\n",
    "\n",
    "- [MeanIOU](https://keras.io/api/metrics/segmentation_metrics/#meaniou-class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model()\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy', 'binary_accuracy', tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "#treina o modelo\n",
    "model1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas Precisão e Revocação\n",
    "\n",
    "Podemos utilizar as métricas Precisão e Revocação caso façamos a alteração da função de perda para `categorical_crossentropy`.\n",
    "\n",
    "Caso contrário, o sistema acusa erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforma o modelo em one hot\n",
    "one_hot_train_labels = tf.one_hot(train_labels, 10)\n",
    "\n",
    "#gera modelo\n",
    "model1 = load_model()\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
    "               metrics=[tf.keras.metrics.Precision(name='precision'), \n",
    "                        tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.PrecisionAtRecall(0.5)])\n",
    "\n",
    "#treina o modelo\n",
    "model1.fit(train_images, one_hot_train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Otimizadores\n",
    "\n",
    "Otimizadores correspondem aos métodos numéricos utilizados para minimização do erro esperado.\n",
    "\n",
    "O objetivo é reduzir a diferença entre a saída predita e a saída esperada.\n",
    "\n",
    "No Tensorflow, o otimizador é definido pelo atributo `optimizer`, ao executar o método `compile` do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos, por padrão usar os seguintes otimizadores:\n",
    "\n",
    "- [SGD](https://keras.io/api/optimizers/sgd/);\n",
    "- [RMSprop](https://keras.io/api/optimizers/rmsprop/);\n",
    "- [Adam](https://keras.io/api/optimizers/adam/);\n",
    "- [Adadelta](https://keras.io/api/optimizers/adadelta/);\n",
    "- [Adagrad](https://keras.io/api/optimizers/adagrad/);\n",
    "- [Adamax](https://keras.io/api/optimizers/adamax/);\n",
    "- [Nadam](https://keras.io/api/optimizers/Nadam/);\n",
    "- [Ftrl](https://keras.io/api/optimizers/ftrl/).\n",
    "\n",
    "É possível configurar esses otimizadores, conforme veremos na sequência, de modo a customizá-los.\n",
    "\n",
    "O Tensorflow ainda permite a criação de otimizadores próprios, que podem ser usados na tentativa de aumentar o desempenho da rede.\n",
    "\n",
    "Mais informações podem ser encontradas no link: https://keras.io/api/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model()\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "model1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "model1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "model1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxa de Aprendizado (*Learning Rate*)\n",
    "\n",
    "A taxa de aprendizado corresponde a taxa de atualização de pesos de uma rede neural. Pode ser entendida como o tamanho do passo em uma dada iteração diminuição da perda da rede.\n",
    "\n",
    "A taxa de aprendizado é frequentemente denotada pela letra $\\eta$ (eta).\n",
    "\n",
    "Podemos definir explicitamente a taxa de aprendizado da rede, com auxílio dos otimizadores. Para isso, devemos utilizar instanciar um objeto correspondente ao otimizador que queremos utilizar e, em seguida, definir a taxa de aprendizado.\n",
    "\n",
    "O valor ideal da taxa de aprendizado pode variar de acordo com o otimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#define o otimizador\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "history = model1.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# plota o gráfico\n",
    "helper.plot_history_training(history, metrics=['accuracy', 'val_accuracy'], legend=['Treinamento', 'Validação'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#define o otimizador\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "history = model1.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# plota o gráfico\n",
    "helper.plot_history_training(history, metrics=['accuracy', 'val_accuracy'], legend=['Treinamento', 'Validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decaimento da Taxa de Aprendizado (*Learning Rate Decay*)\n",
    "\n",
    "Ao definir a taxa de aprendizado, podemos querer que nossa rede inicie com um taxa de aprendizado e, em seguida, a taxa descresça constantemente.\n",
    "\n",
    "Nesse caso, busca-se uma atualização de peso mais brusca no início do treinamento e uma atualização mais suave após algumas épocas, com objetivo de refinamento.\n",
    "\n",
    "Para isso, podemos utilizar uma função de decaimento, que fará com que a função de perda diminua ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#define o decaimento da taxa de aprendizado\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "#define o otimizador\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "history = model1.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# plota o gráfico\n",
    "helper.plot_history_training(history, metrics=['accuracy', 'val_accuracy'], legend=['Treinamento', 'Validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "\n",
    "## Tarefas \n",
    "\n",
    "### Tarefa 1 (30 minutos)\n",
    "\n",
    "Treine a rede desenvolvida na Tarefa 1 - Notebook 2 no conjunto de dados CIFAR-10.\n",
    "\n",
    "Altere os parâmetros de compilação, como otimizadores, funções de perda e as métricas de avaliação.\n",
    "\n",
    "#### Atividades Sugeridas\n",
    "\n",
    "- Altere os otimizadores e veja a diferença na acurácia;\n",
    "- Altere as taxas de aprendizado e decaimento da rede;\n",
    "- Teste algumas funções de perda distintas;\n",
    "- Altere as métricas de avaliação: caso queira, adicione múltiplas métricas.\n",
    "- Plote gráficos para verificar a existência de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insira seu modelo aqui (arquitetura de rede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treine seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprima o gráfico de treinamento aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avalie seu modelo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Tarefa 2 (30 minutos)\n",
    "\n",
    "Treine a rede desenvolvida na tarefa anterior no conjunto de dados CIFAR-100.\n",
    "\n",
    "Comece com o melhor resultado obtido na tarefa anterior e altere os parâmetros de compilação, como otimizadores, taxas de aprendizado e funções de perda.\n",
    "\n",
    "Informações sobre a base de dados: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "![CIFAR 100](https://web.stanford.edu/~hastie/CASI_files/DATA/cifar100.jpg)\n",
    "\n",
    "Fonte: *Trevor Hastie. **CIFAR-100 image database**. Disponível em: https://web.stanford.edu/~hastie/CASI_files/DATA/cifar-100.html. Acesso em: 16 de outubro de 2021.*\n",
    "\n",
    "#### Atividades Sugeridas\n",
    "\n",
    "- Altere os otimizadores e veja a diferença na acurácia;\n",
    "- Altere as taxas de aprendizado e decaimento da rede;\n",
    "- Teste algumas funções de perda distintas;\n",
    "- Altere as métricas de avaliação: caso queira, adicione múltiplas métricas.\n",
    "- Plote gráficos para verificar a existência de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download da base de dados\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "#divisão em base de treinamento e testes (subdividido em imagens e labels)\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
    "\n",
    "#remove 1 dimensão dos arrays de label\n",
    "train_labels = np.squeeze(train_labels)\n",
    "test_labels = np.squeeze(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicao dos nomes das classes CIFAR100\n",
    "class_names_100 = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', \n",
    "    'bed', 'bee', 'beetle', 'bicycle', 'bottle', \n",
    "    'bowl', 'boy', 'bridge', 'bus', 'butterfly', \n",
    "    'camel', 'can', 'castle', 'caterpillar', 'cattle', \n",
    "    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', \n",
    "    'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', \n",
    "    'girl', 'hamster', 'house', 'kangaroo', 'keyboard', \n",
    "    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', \n",
    "    'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', \n",
    "    'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', \n",
    "    'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', \n",
    "    'plain', 'plate', 'poppy', 'porcupine', 'possum', \n",
    "    'rabbit', 'raccoon', 'ray', 'road', 'rocket', \n",
    "    'rose', 'sea', 'seal', 'shark', 'shrew', \n",
    "    'skunk', 'skyscraper', 'snail', 'snake', 'spider', \n",
    "    'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', \n",
    "    'train', 'trout', 'tulip', 'turtle', 'wardrobe', \n",
    "    'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insira seu modelo aqui (arquitetura de rede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treine seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprima o gráfico de treinamento aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avalie seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
