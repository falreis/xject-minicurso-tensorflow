{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IFMG](https://images.even3.com.br/sBWZnWPFUBgLOGciSZc4G5ZQy7Q=/1100x440/smart/even3.blob.core.windows.net/banner/ARTEPARASITE3.993b3db9f908426e9833.png)\n",
    "\n",
    "---\n",
    "\n",
    "# Introdução ao Tensorflow - Parte 2\n",
    "\n",
    "---\n",
    "\n",
    "#### Professor: Felipe Reis\n",
    "\n",
    "#### Data: 20-10-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Importação de bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "#import plot_images\n",
    "from xject_helper import xject_helper as helper\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Base de Dados CIFAR-10\n",
    "\n",
    "A base de dados CIFAR-10 consiste em 60.000 imagens coloridas de 32x32, divididas em 10 classes.\n",
    "Cada classe contém 6.000 imagens por classe. \n",
    "O conjunto é dividido em 50.000 imagens de treinamento e 10.000 imagens de teste.\n",
    "\n",
    "CIFAR é o acrônimo de Canadian Institute For Advanced Research, proprietário da base de dados.\n",
    "O CIFAR-10 e CIFAR-100 são subconjuntos rotulados de uma base de dados de pequenas imagens que contém 80 milhões de amostras. \n",
    "\n",
    "As imagens foram coletadas por Alex Krizhevsky, Vinod Nair e Geoffrey Hinton.\n",
    "\n",
    "A base está disponível em: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "Ela também está disponível na página do Tensorflow: https://www.tensorflow.org/datasets/catalog/cifar10\n",
    "\n",
    "![CIFAR 10](https://cdn-images-1.medium.com/max/1200/1*SZnidBt7CQ4Xqcag6rd8Ew.png)\n",
    "\n",
    "Fonte: *Jannik Zürn. **Training a CIFAR-10 classifier in the cloud using TensorFlow and Google Colab**. 2018. Disponível em: https://jannik-zuern.medium.com/training-a-cifar-10-classifier-in-the-cloud-using-tensorflow-and-google-colab-f3a5fbdfe24d. Acesso em: 05 de outubro de 2021.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download da base de dados\n",
    "cifar10 = keras.datasets.cifar10\n",
    "\n",
    "#divisão em base de treinamento e testes (subdividido em imagens e labels)\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "#remove 1 dimensão dos arrays de label\n",
    "train_labels = np.squeeze(train_labels)\n",
    "test_labels = np.squeeze(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impressão da quantidade de imagens da base\n",
    "print('Conjunto treino: {} amostras'.format(len(train_images)))\n",
    "print('Conjunto teste: {} amostras'.format(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicao dos nomes das classes\n",
    "class_names = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Veado', \n",
    "               'Cachorro', 'Sapo', 'Cavalo', 'Barco', 'Caminhão']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_images(train_images, train_labels, class_names, random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ferramenta KnowYourData (Google Research)\n",
    "\n",
    "Podemos ver mais informações sobre a base de dados utilizando o link abaixo:\n",
    "\n",
    "https://knowyourdata-tfds.withgoogle.com/#tab=STATS&dataset=cifar10\n",
    "\n",
    "O site KnowYourData é mantido pelo Google e contém informações e estatísticas sobre conjuntos de dados.\n",
    "\n",
    "Ele permite realizar uma análise visual do conjunto, para que possamos entender o tipo de informação que desejamos aprender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pré processamento\n",
    "\n",
    "Podemos tentar classificar o conjunto de dados utilizando os mesmos modelos utilizados no Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pré processamento\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_images(train_images, train_labels, class_names, random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Treinamento do Modelo\n",
    "\n",
    "O modelo de rede neural abaixo é baseado na arquitetura existente no Notebook 1.\n",
    "\n",
    "Para adequação ao conjunto CIFAR-10, a entrada foi alterada para suportar imagens de tamanho 32 $\\times$ 32 pixels, com 3 canais de cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo de rede sequencial\n",
    "model1 = keras.Sequential([\n",
    "    #transforma a image em um array de imagens de três dimensões (32 x 32 x 3)\n",
    "    keras.layers.Flatten(input_shape=(32, 32, 3)), \n",
    "    \n",
    "    #Camada de dados totalmente conectadas, com ativação relu\n",
    "    #A camada possui 128 nós (neurônios)\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    #Camada de dados totalmente conectadas, com ativação softmax\n",
    "    #A camada possui 10 nós (neurônios), correspondentes às probabilidades de cada classe (10 classes)\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compila o modelo\n",
    "model1.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurações de Treinamento\n",
    "\n",
    "Nesta seção serão detalhadas as algumas configurações de treinamento, ao utilizar o comando `model.fit`.\n",
    "\n",
    "Informações mais detalhadas e outros parâmetros podem ser encontradas no link: https://keras.io/api/models/model_training_apis/#fit-method\n",
    "\n",
    "*Obs.: Outras operações que influenciam o treinamento, como otimizadores, serão vistas nos próximos notebooks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino e Validação\n",
    "\n",
    "Podemos explicitamente dividir os conjuntos de treino e validação, indicando o percentual de divisão.\n",
    "\n",
    "Para isso, devemos utilizar o atributo `validation_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#realiza o treinamento da rede\n",
    "model1.fit(train_images, train_labels, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tamanho do Batch\n",
    "\n",
    "Podemos indicar o número de amostras utilizadas em um mesmo passo do algoritmo (a cada atualização da função de perda).\n",
    "\n",
    "Para isso, devemos utilizar o atributo `batch_size`.\n",
    "\n",
    "O número de amostras no atributo *batch_size* pode variar de acordo com o tamanho da imagem de entrada, tarefa executada (classificação, segmentação) e capacidade de memória da placa de vídeo.\n",
    "\n",
    "O valor *default* do argumento é 32. No entanto, caso a placa de rede tenha pouca memória, podemos reduzir o tamanho do *batch*, de modo que o número de imagens processadas concomitantemente seja menor. Caso tenhamos memória disponível, podemos aumentar o tamanho do batch de modo a aumentar a velocidade de treinamento.\n",
    "\n",
    "Mais informações podem ser encontradas em: https://keras.io/api/models/model_training_apis/#fit-method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realiza o treinamento da rede\n",
    "model1.fit(train_images, train_labels, batch_size=128, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impressão de Resultados Intermediários\n",
    "\n",
    "Podemos indicar qual o nível de detalhamento das informações a serem exibidas durante o treinamento.\n",
    "\n",
    "Para isso, devemos utilizar o atributo `verbose`.\n",
    "\n",
    "O atributo *verbose* pode ser dividido em 3 níveis:\n",
    "\n",
    "0. ***Silencioso***. Não imprime informações sobre o treinamento.\n",
    "1. ***Barra de Progresso*** (Padrão). Exibe o status do treinamento e uma barra de progresso.\n",
    "2. ***Linha por época***. Exibe uma linha por época durante o treinamento (pode ser usado para criação de *logs*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realiza o treinamento da rede\n",
    "model1.fit(train_images, train_labels, batch_size=128, validation_split=0.2, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#realiza o treinamento da rede\n",
    "model1.fit(train_images, train_labels, batch_size=128, validation_split=0.2, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Épocas de Treinamento\n",
    "\n",
    "O atributo `epochs` é utilizado para definir o número de ciclos de atualização de pesos da rede.\n",
    "\n",
    "Cada ciclo passa por todo o conjunto de dados e denominado época.\n",
    "\n",
    "Ao aumentar em excesso a quantidade de épocas de treinamento, pode-se gerar um problema indesejado, denominado *overfitting*. Esse problema ocorre quando a rede neural passa a decorar as informações, ao invés de generalizar seu conhecimento. Com isso, apesar o desempenho no conjunto de treinamento ser mais alto, a rede terá um desempenho mais baixo no conjunto de testes.\n",
    "\n",
    "\n",
    "![Overfitting](https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/600px-Overfitting.svg.png)\n",
    "Fonte: Wikipedia Contributors. Overfitting. 2021. Disponível em: https://en.wikipedia.org/wiki/Overfitting. Acesso em: 05 de outubro de 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realiza o treinamento da rede\n",
    "model1.fit(train_images, train_labels, batch_size=128, validation_split=0.2, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráfico de treinamento\n",
    "\n",
    "A partir do treinamento da rede neural, podemos gerar um gráfico do treinamento.\n",
    "\n",
    "Tal tarefa pode ser usada para melhor visualização das informações, além da análise de um possível *overfitting* da rede durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(train_images, train_labels, validation_split=0.2, epochs=20, verbose=0)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota o gráfico\n",
    "fig=plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "#exibe legenda, títulos e nomes dos eixos\n",
    "plt.title('Perda do modelo')\n",
    "plt.ylabel('Perda (Loss)')\n",
    "plt.xlabel('Épocas')\n",
    "plt.legend(['treinamento', 'validação'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota o gráfico\n",
    "fig=plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "#exibe legenda, títulos e nomes dos eixos\n",
    "plt.title('Acurácia do modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Épocas')\n",
    "plt.legend(['treinamento', 'validação'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotar Gráfico de Treinamento (Helper)\n",
    "\n",
    "Podemos plotar o gráfico de treinamento com auxílio de uma função criada na classe Helper, utilizando o comando abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plota o gráfico\n",
    "helper.plot_history_training(history, metrics=['accuracy', 'val_accuracy'], legend=['Treinamento', 'Validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliação do modelo\n",
    "test_loss, test_acc = model1.evaluate(test_images,  test_labels)\n",
    "print('Acurácia de testes: %.4f', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "\n",
    "## Tarefas \n",
    "\n",
    "### Tarefa 1 (30 minutos)\n",
    "\n",
    "Treine a rede desenvolvida na Tarefa 2 (Notebook 1) no conjunto de dados CIFAR-10.\n",
    "\n",
    "Para adequação ao conjunto, lembre-se de alterar a entrada para suportar imagens de tamanho 32 $\\times$ 32 pixels, com 3 canais de cores.\n",
    "\n",
    "#### Atividades Sugeridas\n",
    "\n",
    "- Altere o percentual de divisão dos conjuntos de validação e treinamento;\n",
    "- Altere o tamanho do *batch*;\n",
    "- Altere o número de épocas de treinamento;\n",
    "- Escolha um método de impressão de resultados intermediários, para construção de um *log*;\n",
    "- Plote gráficos para verificar a existência de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insira seu modelo aqui (arquitetura de rede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treine seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprima o gráfico de treinamento aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avalie seu modelo aqui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
