{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IFMG](https://images.even3.com.br/sBWZnWPFUBgLOGciSZc4G5ZQy7Q=/1100x440/smart/even3.blob.core.windows.net/banner/ARTEPARASITE3.993b3db9f908426e9833.png)\n",
    "\n",
    "---\n",
    "\n",
    "# Introdução ao Tensorflow - Parte 4\n",
    "\n",
    "---\n",
    "\n",
    "#### Professor: Felipe Reis\n",
    "\n",
    "#### Data: 20-10-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Importação de bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "#import plot_images\n",
    "from xject_helper import xject_helper as helper\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Base de Dados MNIST\n",
    "\n",
    "O banco de dados MNIST contém dígitos manuscritos (escritos a mão).\n",
    "\n",
    "Tem um conjunto de treinamento com 60.000 imagens e um conjunto de teste com 10.000 imagens. \n",
    "\n",
    "Os dígitos foram normalizados por tamanho e centralizados em uma imagem de tamanho fixo.\n",
    "\n",
    "A base de dados foi criada por Yann LeCun em 1998.\n",
    "\n",
    "A base MNIST está disponível em: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "![MNist](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
    "\n",
    "Fonte: *Yann LeCun, Corinna Cortes, Christopher J.C. Burges. **Gradient-based learning applied to document recognition**. 1998. Proceedings of the IEEE, 86(11):2278-2324. Disponível em: http://yann.lecun.com/exdb/mnist/. Acesso em: 11 de outubro de 2021.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download da base de dados\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "#divisão em base de treinamento e testes (subdividido em imagens e labels)\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impressão da quantidade de imagens da base\n",
    "print('Conjunto treino: {} amostras'.format(len(train_images)))\n",
    "print('Conjunto teste: {} amostras'.format(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicao dos nomes das classes\n",
    "#definição das classes \n",
    "class_names = ['Dígito 0', 'Dígito 1', 'Dígito 2', 'Dígito 3', 'Dígito 4', \n",
    "               'Dígito 5', 'Dígito 6', 'Dígito 7', 'Dígito 8', 'Dígito 9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_images(train_images, train_labels, class_names, binary=True, random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pré processamento\n",
    "\n",
    "Podemos classificar o conjunto de dados utilizando os mesmos modelos utilizados no Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pré processamento\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Treinamento do Modelo\n",
    "\n",
    "Os modelos des redes neurais abaixo foram baseado nas arquiteturas existentes no Notebook 1.\n",
    "\n",
    "Para adequação ao conjunto CIFAR-10, a entrada foi alterada para suportar imagens de tamanho 32 $\\times$ 32 pixels, com 3 canais de cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_1():\n",
    "    #modelo de rede sequencial\n",
    "    return keras.Sequential([\n",
    "        #transforma a image em um array de imagens de três dimensões (32 x 32 x 3)\n",
    "        keras.layers.Flatten(input_shape=(28, 28), name='flatten_1'), \n",
    "\n",
    "        #Camada de dados totalmente conectadas, com ativação relu\n",
    "        #A camada possui 128 nós (neurônios)\n",
    "        keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
    "\n",
    "        #Camada de dados totalmente conectadas, com ativação softmax\n",
    "        #A camada possui 10 nós (neurônios), correspondentes às probabilidades de cada classe (10 classes)\n",
    "        keras.layers.Dense(10, activation='softmax', name='output')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera modelo\n",
    "model1 = load_model_1() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#define o otimizador\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "history = model1.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# plota o gráfico\n",
    "helper.plot_history_training(history, metrics=['accuracy'], legend=['Treinamento'], ylabel='Acurácia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Armazenamento e Recuperação de Pesos\n",
    "\n",
    "Suponha que uma rede neural foi treinada durante um período de tempo. Após esse período, a rede será utilizada em uma aplicação. \n",
    "\n",
    "Neste cenário, é necessário o armazenamento de pesos da rede, de modo a evitar que sejam realizados novos treinamentos.\n",
    "\n",
    "O armazenamento de pesos também pode ser usado em caso de interrupção do treinamento, permitindo que a rede não precise ser treinada desde o início novamente.\n",
    "\n",
    "Esta seção contém os códigos necessários para armazenamento e recuperação de pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação de Checkpoints\n",
    "\n",
    "Para armazenar os pesos da rede, podemos criar checkpoints, que serão utilizados para salvar pesos com uma determinada frequência.\n",
    "\n",
    "O código abaixo contém um checkpoint para uma rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define diretório onde o arquivo será salvo\n",
    "checkpoint_path = 'models/model.hdf5'\n",
    "\n",
    "#cria o checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a criação do checkpoints, podemos adicioná-lo ao treinamento, dentro do método `model.fit`.\n",
    "\n",
    "O parâmetro `callback` recebe uma método, que é invocado após o fim de uma época. É possível passar uma lista de callbacks para o treinamento da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#treina o modelo\n",
    "history = model1.fit(train_images, train_labels, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos alterar o checkpoint para salvar a execução somente se a rede melhorar seu desempenho em uma determinada métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define diretório onde o arquivo será salvo\n",
    "checkpoint_path = 'models/model.hdf5'\n",
    "\n",
    "#cria o checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='accuracy', \n",
    "                                                save_weights_only=True, save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treina o modelo\n",
    "history = model1.fit(train_images, train_labels, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Recuperação de Pesos\n",
    "\n",
    "Podemos recuperar os pesos antes do início do treinamento da rede. Para isso, devemos criar o modelo e em seguida carregar os pesos com auxílio do método `load_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define diretório onde o arquivo será salvo\n",
    "checkpoint_path = 'models/model.hdf5'\n",
    "\n",
    "#gera modelo\n",
    "model1 = load_model_1() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#carrega os pesos\n",
    "model1.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após carregar os pesos, podemos executar o treinamento da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define o otimizador\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "history = model1.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Transfer Learning\n",
    "\n",
    "*Transfer Learning* ou Transferência de Aprendizado corresponde à tarefa de aproveitar o conhecimento obtido em uma tarefa e aplicá-lo à outra.\n",
    "\n",
    "Em redes neurais, esse conceito é associado à tarefa de reaproveitamento de pesos em tarefas diferentes.\n",
    "\n",
    "#### *Transfer Learning* MNIST para Fashion MNIST\n",
    "\n",
    "Suponha que uma rede foi treinada na base de dados MNIST. Após o treinamento, deseja-se que a rede seja utilizada na base Fashion MNIST.\n",
    "\n",
    "As bases de dados são distintas, porém o conhecimento obtido pela rede na base MNIST pode ser utilizado para auxiliar no treinamento da base Fashion MNIST. Devido a características da rede, algumas *features*, principalmente das camadas iniciais da rede podem ser semelhantes. \n",
    "\n",
    "Aproveitar os pesos de uma rede em outra pode diminuir o número de épocas necessárias para treinamento. No entanto, para alguns modelos, o uso de pesos diferentes pode não causar nenhuma melhoria ou, até mesmo, piorar o desempenho da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download da base de dados\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "#divisão em base de treinamento e testes (subdividido em imagens e labels)\n",
    "(fash_tr_images, fash_tr_labels), (fash_te_images, fash_te_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pré processamento\n",
    "fash_tr_images = fash_tr_images / 255.0\n",
    "fash_te_images = fash_te_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento da rede com Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define diretório onde o arquivo será salvo\n",
    "checkpoint_path = 'models/model.hdf5'\n",
    "\n",
    "#gera modelo\n",
    "model1 = load_model_1() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#carrega os pesos da rede MNIST\n",
    "model1.load_weights(checkpoint_path)\n",
    "\n",
    "#define o otimizador\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#compila o modelo\n",
    "model1.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "history = model1.fit(fash_tr_images, fash_tr_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Transfer Learning entre Redes Diferentes\n",
    "\n",
    "Podemos utilizar os pesos de uma rede em uma arquitetura de rede diferente (desde que semelhante).\n",
    "\n",
    "Como indicado no exemplo anterior, esta tarefa também tem como objetivo diminuir o tempo de treinamento de uma rede neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de Dados MNIST\n",
    "\n",
    "Na tarefa atual, carregaremos um novo modelo de dados, contendo mais nós, semelhante ao recomendado no Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_2():\n",
    "    #modelo de rede sequencial\n",
    "    return keras.Sequential([\n",
    "        #transforma a image em um array de imagens de três dimensões (32 x 32 x 3)\n",
    "        keras.layers.Flatten(input_shape=(28, 28), name='flatten_1'), \n",
    "\n",
    "        #Camada de dados totalmente conectadas, com ativação relu\n",
    "        #A camada possui 128 nós (neurônios)\n",
    "        keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
    "        keras.layers.Dense(128,  activation='relu', name='dense_2'),\n",
    "        keras.layers.Dense(128,  activation='relu', name='dense_3'),\n",
    "\n",
    "        #Camada de dados totalmente conectadas, com ativação softmax\n",
    "        #A camada possui 10 nós (neurônios), correspondentes às probabilidades de cada classe (10 classes)\n",
    "        keras.layers.Dense(10, activation='softmax', name='output')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos os pesos da rede 1.\n",
    "\n",
    "É importante salientar que essa operação somente é valida caso as redes neurais sejam compatíveis. \n",
    "\n",
    "Em caso de arquiteturas de rede muito distintas, tal processo não irá funcionar adequadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define diretório onde o arquivo será salvo\n",
    "checkpoint_path = 'models/model.hdf5'\n",
    "\n",
    "#gera modelo\n",
    "model2 = load_model_2() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#carrega os pesos da rede MNIST\n",
    "model2.load_weights(checkpoint_path, by_name=True)\n",
    "\n",
    "#define o otimizador\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#compila o modelo\n",
    "model2.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "history = model2.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento somente de algumas camadas da rede\n",
    "\n",
    "Se fazemos o *transfer learning* para uma mesma arquitetura de rede neural, pode não ser necessário o treinamento de todas as camadas da rede. \n",
    "\n",
    "Em redes diferentes, podemos apenas treinar as novas camadas. Esse procedimento reduz o tempo de treinamento, uma vez que os pesos dessas camadas estarão congelados. Caso queira, os pesos podem ser descongelados em um segundo momento, para refinamento de valores.\n",
    "\n",
    "O parâmetro que indica que uma camada deve ser treinada é o `trainable`. Por padrão, esse parâmetro é verdadeiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_3():\n",
    "    #modelo de rede sequencial\n",
    "    return keras.Sequential([\n",
    "        #transforma a image em um array de imagens de três dimensões (32 x 32 x 3)\n",
    "        keras.layers.Flatten(input_shape=(28, 28), name='flatten_1', trainable=False), \n",
    "\n",
    "        #Camada de dados totalmente conectadas, com ativação relu\n",
    "        #A camada possui 128 nós (neurônios)\n",
    "        keras.layers.Dense(128, activation='relu', name='dense_1', trainable=False),\n",
    "        keras.layers.Dense(128,  activation='relu', name='dense_2'),\n",
    "        keras.layers.Dense(128,  activation='relu', name='dense_3'),\n",
    "\n",
    "        #Camada de dados totalmente conectadas, com ativação softmax\n",
    "        #A camada possui 10 nós (neurônios), correspondentes às probabilidades de cada classe (10 classes)\n",
    "        keras.layers.Dense(10, activation='softmax', name='output')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define diretório onde o arquivo será salvo\n",
    "checkpoint_path = 'models/model.hdf5'\n",
    "\n",
    "#gera modelo\n",
    "model3 = load_model_3() #o modelo foi recarregado para melhor comparação dos otimizadores\n",
    "\n",
    "#carrega os pesos da rede MNIST\n",
    "model3.load_weights(checkpoint_path, by_name=True)\n",
    "\n",
    "#define o otimizador\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#compila o modelo\n",
    "model3.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#treina o modelo\n",
    "history = model3.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "\n",
    "## Tarefas \n",
    "\n",
    "### Tarefa 1 (40 minutos)\n",
    "\n",
    "Treine um conjunto de dados no modelo CIFAR-10 e salve os pesos. \n",
    "\n",
    "Faça o carregamento dos pesos para treinamento do conjunto CIFAR-100. Será necessário alterar a última camada da rede, devido ao número de classes na saída.\n",
    "\n",
    "#### Atividades Sugeridas\n",
    "\n",
    "- Utilize uma arquitetura de rede simples com mais de 3 camadas;\n",
    "- Congele camadas ao treinar a rede CIFAR-100;\n",
    "- Compare o treinamento da rede congelada com uma rede sem congelamento.\n",
    "- Verifique se após descongelar os pesos, o desempenho do treinamento da rede melhora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insira seu modelo aqui (arquitetura de rede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treine seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprima o gráfico de treinamento aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avalie seu modelo aqui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
